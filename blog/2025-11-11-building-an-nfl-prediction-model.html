<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>How to Build an NFL Prediction Model with ELO Ratings and DuckDB | Michelle Pellon</title>

  <meta name="description" content="Learn how to build an NFL prediction model using ELO ratings, Monte Carlo simulations, DuckDB, and dbt. Covers mathematical methodology, data engineering architecture, and model performance validation." />
  <meta name="keywords" content="NFL predictions, ELO rating system, sports analytics, data engineering, DuckDB, dbt, Monte Carlo simulation, machine learning, predictive modeling, FiveThirtyEight, Brier score, model calibration" />
  <meta name="author" content="Michelle Pellon" />
  <meta name="robots" content="index, follow" />

  <!-- Canonical URL -->
  <link rel="canonical" href="https://michellepellon.com/blog/2025-11-11-building-an-nfl-prediction-model" />

  <!-- Open Graph Tags -->
  <meta property="og:title" content="How to Build an NFL Prediction Model with ELO Ratings and DuckDB" />
  <meta property="og:description" content="Learn how to build an NFL prediction model using ELO ratings, Monte Carlo simulations, DuckDB, and dbt. Covers mathematical methodology, data engineering architecture, and model performance validation." />
  <meta property="og:image" content="https://michellepellon.com/img/michelle-pellon-headshot.jpg" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />
  <meta property="og:url" content="https://michellepellon.com/blog/2025-11-11-building-an-nfl-prediction-model" />
  <meta property="og:type" content="article" />
  <meta property="og:site_name" content="Michelle Pellon" />
  <meta property="og:article:author" content="Michelle Pellon" />
  <meta property="og:article:published_time" content="2025-11-11T00:00:00Z" />
  <meta property="og:article:tag" content="Data Engineering" />
  <meta property="og:article:tag" content="Sports Analytics" />
  <meta property="og:article:tag" content="Machine Learning" />
  <meta property="og:article:tag" content="DuckDB" />

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="How to Build an NFL Prediction Model with ELO Ratings and DuckDB" />
  <meta name="twitter:description" content="Learn how to build an NFL prediction model using ELO ratings, Monte Carlo simulations, DuckDB, and dbt. Covers mathematical methodology, data engineering architecture, and model performance validation." />
  <meta name="twitter:image" content="https://michellepellon.com/img/michelle-pellon-headshot.jpg" />
  <meta name="twitter:creator" content="@michellepellon" />

  <!-- Favicon -->
  <link rel="icon" href="../img/favicon.ico" type="image/x-icon" />
  <link rel="apple-touch-icon" href="../img/apple-touch-icon.png" />

  <!-- Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "How to Build an NFL Prediction Model with ELO Ratings and DuckDB",
    "alternativeHeadline": "Mathematical Methodology and Data Engineering Architecture",
    "image": "https://michellepellon.com/img/michelle-pellon-headshot.jpg",
    "author": {
      "@type": "Person",
      "name": "Michelle Pellon",
      "url": "https://michellepellon.com",
      "sameAs": [
        "https://www.linkedin.com/in/michelle-pellon/",
        "https://github.com/michellepellon"
      ]
    },
    "publisher": {
      "@type": "Person",
      "name": "Michelle Pellon",
      "logo": {
        "@type": "ImageObject",
        "url": "https://michellepellon.com/img/michelle-pellon-headshot.jpg"
      }
    },
    "datePublished": "2025-11-11",
    "dateModified": "2025-11-11",
    "description": "Learn how to build an NFL prediction model using ELO ratings, Monte Carlo simulations, DuckDB, and dbt. Covers mathematical methodology, data engineering architecture, and model performance validation.",
    "keywords": "NFL predictions, ELO rating system, sports analytics, data engineering, DuckDB, dbt, Monte Carlo simulation, Brier score, model calibration",
    "url": "https://michellepellon.com/blog/2025-11-11-building-an-nfl-prediction-model",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https://michellepellon.com/blog/2025-11-11-building-an-nfl-prediction-model"
    },
    "articleSection": "Data Engineering",
    "wordCount": 2800,
    "inLanguage": "en-US"
  }
  </script>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-TPVXJT8FKZ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-TPVXJT8FKZ');
  </script>

  <!-- Cookie Consent -->
  <script src="../cookie-consent.min.js" defer></script>

  <!-- MathJax -->
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">

  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    :root {
      --max-width: 1100px;
      --article-width: 800px;
      --text-primary: #000000;
      --text-secondary: #666666;
      --text-muted: #999999;
      --link-color: #000000;
      --link-hover: #4d65ff;
      --accent-blue: #4d65ff;
      --border-color: #e5e5e5;
      --bg-white: #ffffff;
      --bg-light: #fafafa;
      --bg-code: #f6f8fa;
      --spacing-xs: 0.5rem;
      --spacing-sm: 1rem;
      --spacing-md: 1.5rem;
      --spacing-lg: 2rem;
      --spacing-xl: 3rem;
      --spacing-2xl: 4rem;
      --spacing-3xl: 6rem;
      --shadow-sm: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);
      --shadow-md: 0 3px 6px rgba(0,0,0,0.15), 0 2px 4px rgba(0,0,0,0.12);
    }

    html {
      font-size: 16px;
      -webkit-font-smoothing: antialiased;
      -moz-osx-font-smoothing: grayscale;
      text-rendering: optimizeLegibility;
    }

    body {
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen', 'Ubuntu', 'Cantarell', 'Fira Sans', 'Droid Sans', 'Helvetica Neue', sans-serif;
      font-size: 1rem;
      line-height: 1.6;
      color: var(--text-primary);
      background: var(--bg-white);
      font-weight: 400;
    }

    .container {
      max-width: var(--max-width);
      margin: 0 auto;
      padding: 0 var(--spacing-lg);
    }

    .article-container {
      max-width: var(--article-width);
      margin: 0 auto;
      padding: 0 var(--spacing-lg);
    }

    /* Typography */
    h1 {
      font-size: 2.5rem;
      font-weight: 700;
      line-height: 1.2;
      letter-spacing: -0.03em;
      margin-bottom: var(--spacing-md);
    }

    h2 {
      font-size: 1.875rem;
      font-weight: 600;
      line-height: 1.3;
      letter-spacing: -0.02em;
      margin-top: var(--spacing-2xl);
      margin-bottom: var(--spacing-lg);
    }

    h3 {
      font-size: 1.5rem;
      font-weight: 600;
      line-height: 1.3;
      margin-top: var(--spacing-xl);
      margin-bottom: var(--spacing-md);
    }

    h4 {
      font-size: 1.25rem;
      font-weight: 600;
      line-height: 1.4;
      margin-top: var(--spacing-lg);
      margin-bottom: var(--spacing-sm);
    }

    p {
      margin-bottom: var(--spacing-md);
      color: var(--text-secondary);
    }

    strong {
      font-weight: 600;
      color: var(--text-primary);
    }

    /* Navigation */
    nav {
      padding: var(--spacing-lg) 0;
      border-bottom: 1px solid var(--border-color);
      margin-bottom: var(--spacing-2xl);
    }

    .nav-content {
      display: flex;
      justify-content: space-between;
      align-items: center;
    }

    .nav-brand {
      font-weight: 600;
      font-size: 1.125rem;
      text-decoration: none;
      color: var(--text-primary);
    }

    .nav-links {
      display: flex;
      gap: var(--spacing-lg);
      list-style: none;
    }

    .nav-links a {
      text-decoration: none;
      color: var(--text-secondary);
      font-size: 0.9375rem;
      transition: color 0.2s;
    }

    .nav-links a:hover {
      color: var(--text-primary);
    }

    /* Article Header */
    .article-header {
      margin-bottom: var(--spacing-2xl);
    }

    .article-meta {
      display: flex;
      gap: var(--spacing-md);
      align-items: center;
      color: var(--text-muted);
      font-size: 0.875rem;
      margin-bottom: var(--spacing-md);
    }

    .article-date {
      color: var(--text-muted);
    }

    .reading-time {
      color: var(--text-muted);
    }

    .article-tags {
      display: flex;
      gap: var(--spacing-xs);
      flex-wrap: wrap;
      margin-top: var(--spacing-md);
    }

    .tag {
      display: inline-block;
      padding: 0.25rem 0.75rem;
      background: var(--bg-light);
      color: var(--text-secondary);
      font-size: 0.8125rem;
      border-radius: 4px;
      text-decoration: none;
      transition: background 0.2s;
    }

    .tag:hover {
      background: var(--bg-code);
    }

    /* Article Content */
    .article-content {
      font-size: 1.0625rem;
      line-height: 1.7;
      color: var(--text-secondary);
    }

    .article-content a {
      color: var(--link-color);
      text-decoration: none;
      border-bottom: 1px solid var(--border-color);
      transition: border-color 0.2s;
    }

    .article-content a:hover {
      border-bottom-color: var(--link-hover);
      color: var(--link-hover);
    }

    .article-content ul, .article-content ol {
      margin: var(--spacing-md) 0;
      padding-left: var(--spacing-lg);
    }

    .article-content li {
      margin-bottom: var(--spacing-sm);
    }

    .article-content code {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.875rem;
      background: var(--bg-code);
      padding: 0.2em 0.4em;
      border-radius: 3px;
    }

    .article-content pre {
      background: var(--bg-code);
      padding: var(--spacing-md);
      border-radius: 6px;
      overflow-x: auto;
      margin: var(--spacing-md) 0;
    }

    .article-content pre code {
      background: none;
      padding: 0;
    }

    .article-content blockquote {
      border-left: 3px solid var(--accent-blue);
      padding-left: var(--spacing-md);
      margin: var(--spacing-lg) 0;
      font-style: italic;
      color: var(--text-secondary);
    }

    .article-content table {
      width: 100%;
      border-collapse: collapse;
      margin: var(--spacing-md) 0;
    }

    .article-content th, .article-content td {
      border: 1px solid var(--border-color);
      padding: 0.75rem;
      text-align: left;
    }

    .article-content th {
      background: var(--bg-light);
      font-weight: 600;
    }

    /* Footer */
    footer {
      margin-top: var(--spacing-3xl);
      padding: var(--spacing-2xl) 0;
      border-top: 1px solid var(--border-color);
      text-align: center;
      color: var(--text-muted);
      font-size: 0.875rem;
    }

    .back-link {
      display: inline-block;
      margin-bottom: var(--spacing-2xl);
      color: var(--text-secondary);
      text-decoration: none;
      font-size: 0.9375rem;
      transition: color 0.2s;
    }

    .back-link:hover {
      color: var(--text-primary);
    }

    /* Responsive */
    @media (max-width: 768px) {
      html {
        font-size: 15px;
      }

      h1 {
        font-size: 2rem;
      }

      h2 {
        font-size: 1.5rem;
      }

      h3 {
        font-size: 1.25rem;
      }

      .nav-links {
        gap: var(--spacing-md);
      }
    }
  </style>
</head>

<body>
  <nav>
    <div class="container">
      <div class="nav-content">
        <a href="../index.html" class="nav-brand">Michelle Pellon</a>
        <ul class="nav-links">
          <li><a href="../blog.html">Blog</a></li>
          <li><a href="../services.html">Services</a></li>
        </ul>
      </div>
    </div>
  </nav>

  <article class="article-container">
    <a href="../blog.html" class="back-link">← Back to Blog</a>

    <header class="article-header">
      <h1>How to Build an NFL Prediction Model with ELO Ratings and DuckDB</h1>
      <div class="article-meta">
        <time class="article-date" datetime="2025-11-11">November 11, 2025</time>
        <span class="reading-time">12 min read</span>
      </div>
      <div class="article-tags">
        <span class="tag">Data Engineering</span>
        <span class="tag">Sports Analytics</span>
        <span class="tag">DuckDB</span>
        <span class="tag">Machine Learning</span>
      </div>
    </header>

    <div class="article-content">
      <p>I built an NFL prediction model that achieves 57% accuracy across 10 weeks of the 2025 season. The model uses <a href="https://en.wikipedia.org/wiki/Elo_rating_system">ELO ratings</a> and <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo simulations</a> and runs on a modern data stack built with <a href="https://duckdb.org/">DuckDB</a> and <a href="https://www.getdbt.com/">dbt</a>. Week 10 scored 71% accuracy with a <a href="https://en.wikipedia.org/wiki/Brier_score">Brier score</a> of 0.199. This post explains the mathematics, data engineering architecture, current results, and upcoming features.</p>

      <h2>The ELO Rating System</h2>

      <p>The ELO rating system, created by physicist Arpad Elo in the 1960s for chess, measures competitive strength on a single numerical scale. Originally designed to rank chess players, the system has proven remarkably adaptable: it now ranks everything from competitive video game players to NFL teams. The elegance lies in its simplicity: every contest between two competitors updates both ratings based on the expected versus actual outcome.</p>

      <p>In my model, teams start at 1505 points (slightly above the league average of 1500 to account for expansion teams). Winning teams gain points; losing teams lose points. The system rewards upsets heavily: a weak team beating a strong team causes a large rating swing. Conversely, when favorites win as expected, ratings barely move. The formula also accounts for margin of victory: blowout wins matter more than narrow victories.</p>

      <p>The core calculation updates ratings after each game:</p>

      <p>$$\Delta_{\text{ELO}} = K \times \text{MOV}_{\text{multiplier}} \times (S - E)$$</p>

      <p>Where:</p>
      <ul>
        <li>$K = 20$ (learning rate controlling how quickly ratings change)</li>
        <li>$S$ = actual result: 1 (visiting win), 0 (home win), 0.5 (tie)</li>
        <li>$E$ = expected result (win probability for the visiting team)</li>
      </ul>

      <p>The expected result uses the logistic function:</p>

      <p>$$E = \frac{1}{1 + 10^{-(\text{ELO}_{\text{visiting}} - \text{ELO}_{\text{home}} - \text{HFA}) / 400}}$$</p>

      <p>Where HFA is the home field advantage (48 ELO points).</p>

      <p>The margin of victory multiplier scales the rating change based on point differential and the pre-game rating gap:</p>

      <p>$$\text{MOV}_{\text{multiplier}} = \ln(|\text{margin}| + 1) \times \frac{2.2}{|\Delta_{\text{ELO}}| \times 0.001 + 2.2}$$</p>

      <p>This ensures that blowouts between evenly matched teams move ratings more than blowouts where the favorite was expected to dominate.</p>

      <h3>Home Field Advantage</h3>

      <p>Home teams receive a 48 ELO point bonus before calculating win probabilities. This adjustment exists because home teams win more than 50% of NFL games—historically around 57% across the league. The causes are well documented: familiar facilities, supportive crowds, no travel fatigue, sleeping in your own bed, and officiating bias. By adding points to the home team's rating before running the prediction formula, the model accounts for this empirical reality without claiming the home team is genuinely "better."</p>

      <p>For two evenly matched 1500-rated teams, home field advantage shifts the expected win probability from 50% to 57.5%—matching the historical data. I calibrated this value to <a href="https://fivethirtyeight.com/methodology/how-our-nfl-predictions-work/">FiveThirtyEight's rolling 10-year average</a> (48 points), down from an initial 52 points. Home field advantage has gradually declined across the NFL as teams invest in climate-controlled stadiums and improved travel logistics, reducing some of the environmental factors that once favored home teams.</p>

      <h3>Margin of Victory Adjustments</h3>

      <p>The margin-of-victory multiplier prevents the system from treating all wins equally. A narrow 3-point victory suggests the teams were evenly matched; ratings should barely change. A 30-point blowout reveals a significant talent gap; ratings should shift dramatically. The logarithmic scaling $\ln(|\text{margin}| + 1)$ prevents extreme outliers from dominating the system—a 50-point win doesn't count twice as much as a 25-point win.</p>

      <p>The second term $\frac{2.2}{|\Delta_{\text{ELO}}| \times 0.001 + 2.2}$ adjusts for pre-game expectations. When a heavy favorite wins by 30 points, that outcome was expected; ratings barely move. When two evenly matched teams play and one dominates by 30 points, that outcome was surprising; ratings shift substantially. This prevents the system from overreacting to predictable blowouts while still capturing genuinely dominant performances.</p>

      <h3>Bye Week Bonus</h3>

      <p>Teams coming off a bye week receive a temporary 25 ELO point boost for that single game. The NFL schedules bye weeks mid-season to give teams rest. The data shows that rested teams with extra preparation time win more frequently than their season-long ratings would predict. This 25-point adjustment (roughly a 3-4% win probability boost) captures that advantage without permanently inflating the team's rating. After the game, the bonus disappears and ratings return to their normal values.</p>

      <h2>Calibration and Performance Metrics</h2>

      <p>Predictions mean nothing without validation. I track three metrics to measure accuracy:</p>

      <h3>Brier Score</h3>

      <p>Brier score measures the squared error of probabilistic predictions. The formula averages the squared difference between predicted probabilities and actual outcomes. Random guessing scores 0.5; perfect predictions score 0.0. My model scores 0.242 across the 2025 season.</p>

      <h3>Log Loss</h3>

      <p>Log loss penalizes confident but wrong predictions heavily. Predicting 95% probability for a team that loses hurts more than predicting 55% for that same team. Current log loss: 0.677 (lower is better).</p>

      <h3>Accuracy</h3>

      <p>Straight-up accuracy counts how many games the model gets right. Current performance: 57.4% across 10 weeks. Week 10 alone: 71.4% (10 correct out of 14 games).</p>

      <h3>Confidence Intervals</h3>

      <p>Every prediction includes 95% confidence intervals. A 75% playoff probability shows as "75% [73% - 77%]" instead of just "75%". The Wilson Score method calculates intervals for binary outcomes. Empirical percentiles handle continuous metrics like expected wins.</p>

      <h2>Data Engineering Architecture</h2>

      <p>The model runs on a modern, single-node data stack. No Spark clusters, no Kubernetes complexity. One DuckDB database file holds everything.</p>

      <h3>Data Sources</h3>

      <p>Live game data flows from the ESPN API. Historical data comes from Pro Football Reference via the <code>nflreadpy</code> library. Vegas win totals provide optional preseason calibration. All data lands in CSV files first, then transforms into Parquet for the pipeline.</p>

      <h3>Pipeline: Bronze, Silver, Gold</h3>

      <p>The dbt pipeline follows the medallion architecture:</p>

      <p><strong>Bronze Layer</strong> reads raw Parquet files as DuckDB external tables. Four tables cover results, schedules, team ratings, and enhanced features (weather, injuries, rest days).</p>

      <p><strong>Silver Layer</strong> calculates ELO ratings in chronological order. The Python model <code>nfl_elo_rollforward.py</code> processes every game sequentially, maintaining running ELO ratings. Each row shows pre-game ratings, the predicted winner, the actual result, and the ELO change.</p>

      <p><strong>Gold Layer</strong> aggregates analytics-ready views. These include playoff probabilities, calibration curves, weekly performance metrics, and game-by-game predictions.</p>

      <h3>Monte Carlo Simulation</h3>

      <p>The playoff simulator runs 10,000 scenarios of the remaining regular season. Each scenario:</p>

      <ol>
        <li>Simulates every unplayed game using current ELO ratings</li>
        <li>Applies all 8 NFL tiebreaker rules to determine playoff seeding</li>
        <li>Records final standings, playoff teams, and seed assignments</li>
      </ol>

      <p>Aggregating across all scenarios yields playoff probabilities, bye probabilities, expected wins, and seed distributions. A team reaching the playoffs in 7,500 of 10,000 scenarios gets a 75% playoff probability.</p>

      <h3>Technology Stack</h3>

      <ul>
        <li><strong><a href="https://duckdb.org/">DuckDB</a></strong> - Embedded SQL database, single-file design, blazingly fast</li>
        <li><strong><a href="https://www.getdbt.com/">dbt</a></strong> - Data transformation framework with built-in testing</li>
        <li><strong>Parquet</strong> - Columnar storage format for intermediate data</li>
        <li><strong>Python</strong> - Complex logic (ELO calculations, tiebreakers)</li>
        <li><strong>uv</strong> - Python package manager, replaces pip and virtualenv</li>
      </ul>

      <h2>Week 10 Results</h2>

      <p>Week 10 just completed. The model predicted 14 games with these results:</p>

      <ul>
        <li><strong>Accuracy:</strong> 71.4% (10 correct out of 14)</li>
        <li><strong>Brier Score:</strong> 0.199 (Excellent)</li>
        <li><strong>Log Loss:</strong> 0.584</li>
      </ul>

      <p>Notable correct predictions:</p>
      <ul>
        <li>New England Patriots over Tampa Bay Buccaneers (predicted 77% probability)</li>
        <li>Chicago Bears over New York Giants (predicted 76% probability)</li>
        <li>Seattle Seahawks over Arizona Cardinals (predicted 73% probability)</li>
        <li>Denver Broncos over Las Vegas Raiders (predicted 71% probability)</li>
        <li>Houston Texans over Jacksonville Jaguars (predicted 69% probability)</li>
      </ul>

      <p>The model missed 4 games:</p>
      <ul>
        <li>New Orleans Saints beat Carolina Panthers (model favored Carolina, 59%)</li>
        <li>Miami Dolphins beat Buffalo Bills (model favored Buffalo, 68%)</li>
        <li>Los Angeles Rams beat San Francisco 49ers (model favored 49ers, 61%)</li>
        <li>Detroit Lions beat Washington Commanders (model favored Washington, 59%)</li>
      </ul>

      <p>All four misses involved favorites losing: three were home favorites upset by road teams (Carolina, San Francisco, Washington), and one was a road favorite upset by the home underdog (Buffalo losing at Miami). The Miami-Buffalo game was the biggest miss: the 68% favorite Buffalo lost convincingly 13-30. The other three losses came on predictions between 59-61%, all close calls.</p>

      <h2>Comparing to FiveThirtyEight</h2>

      <p>My model achieves 76% feature parity with FiveThirtyEight's NFL predictions. The core ELO system nearly matches theirs. Both use the same K-factor (20), ELO scale (400), margin-of-victory multiplier (2.2), and home field advantage (48 points).</p>

      <p>The major differences:</p>

      <h3>What I Have</h3>
      <ul>
        <li>Core ELO with margin-of-victory adjustments</li>
        <li>Home field advantage (48 points)</li>
        <li>Bye week tracking (+25 ELO)</li>
        <li>Preseason mean reversion with Vegas integration</li>
        <li>Comprehensive NFL tiebreaker implementation (all 8 rules)</li>
        <li>Confidence intervals on all probability estimates</li>
      </ul>

      <h3>What I'm Missing</h3>
      <ul>
        <li><strong>QB VALUE System</strong> - FiveThirtyEight adjusts team ratings based on quarterback performance. A team losing its star QB immediately drops 80 ELO points. My model treats all teams as fixed units.</li>
        <li><strong>Hot Simulations</strong> - My Monte Carlo runs use fixed ELO ratings for all scenarios. FiveThirtyEight updates ratings during simulations, capturing momentum effects. A team winning its first simulated game gets a rating boost for subsequent simulated games.</li>
        <li><strong>Travel Distance</strong> - FiveThirtyEight penalizes teams traveling long distances (roughly -4 ELO per 1,000 miles). My model ignores geography.</li>
        <li><strong>Locked Playoff Seeds</strong> - FiveThirtyEight detects when teams rest starters in Week 18 after clinching playoff position. My model assumes full effort every game.</li>
      </ul>

      <h2>What's Coming Next</h2>

      <p>Four major features will close the gap with FiveThirtyEight:</p>

      <h3>1. Hot Simulations (Impact: +20% accuracy)</h3>

      <p>Currently, my simulator treats team strength as static. A team with 1650 ELO plays all remaining games at 1650, regardless of simulated outcomes. Hot simulations update ratings within each scenario. A team winning its first simulated game gains ELO before its second simulated game.</p>

      <p>This captures momentum. Teams on winning streaks get stronger; teams spiraling downward get weaker. The effect matters most in tight playoff races where a single win or loss swings probabilities significantly.</p>

      <p>Implementation requires refactoring the SQL simulator into Python to maintain per-scenario state. Estimated effort: 500 lines, 2-3 days.</p>

      <h3>2. QB VALUE System (Impact: +10-20% for QB changes)</h3>

      <p>Quarterback performance drives NFL outcomes more than any other position. Elite quarterbacks add 80+ ELO points; backups subtract 30-50 points. The current model treats the 2024 Kansas City Chiefs (Patrick Mahomes) the same as the 2024 Kansas City Chiefs (backup QB). That's wrong.</p>

      <p>FiveThirtyEight's VALUE formula quantifies QB performance:</p>

      <pre><code>VALUE = -2.2×Attempts + 3.7×Completions + (Yards/5) +
        11.3×TDs - 14.1×INTs - 8×Sacks - 1.1×RushAtt +
        0.6×RushYds + 15.9×RushTDs</code></pre>

      <p>QB ELO adjustment scales VALUE by 3.3. Individual QB VALUE updates every 10 games; team rolling average updates every 20 games.</p>

      <p>Implementation needs ESPN API integration for real-time QB stats. Estimated effort: 300 lines, 2-3 days.</p>

      <h3>3. Travel Distance Adjustments (Impact: +1-2%)</h3>

      <p>Long travel hurts performance. FiveThirtyEight penalizes teams roughly -4 ELO per 1,000 miles traveled. Seattle flying to Miami (2,700 miles) loses 11 ELO points before kickoff.</p>

      <p>Implementation requires geocoding all 32 stadiums and calculating great-circle distances. Estimated effort: 100 lines, 1 day.</p>

      <h3>4. Locked Playoff Seed Detection (Impact: ~1%)</h3>

      <p>Teams resting starters in Week 18 after clinching playoff position get a -250 ELO penalty. This creates a circular dependency: simulations inform playoff status, which adjusts game predictions, which feed back into simulations.</p>

      <p>Implementation needs iterative convergence logic. Estimated effort: 200 lines, 1-2 days.</p>

      <h2>Data Engineering Lessons</h2>

      <p>Building this model taught me several lessons:</p>

      <h3>DuckDB is Fast Enough</h3>

      <p>The entire pipeline processes 5 years of historical data, runs 10,000 Monte Carlo scenarios, and generates all analytics in under 10 seconds. No distributed systems, no Spark, no Kubernetes. One laptop, one DuckDB file.</p>

      <h3>Parquet + DuckDB is the New CSV + Postgres</h3>

      <p>Parquet files serve as both storage format and interchange format. DuckDB reads Parquet faster than Postgres reads from disk. The combination eliminates the traditional extract-transform-load bottleneck.</p>

      <h3>Python + SQL Beats Pure SQL</h3>

      <p>ELO calculations and tiebreaker logic belong in Python, not SQL. The 20,000-line tiebreaker model would be unmaintainable in SQL. Python models in dbt give the best of both worlds: SQL for set-based operations, Python for complex logic.</p>

      <h3>Testing Matters More Than Fancy Models</h3>

      <p>My biggest technical debt: zero unit tests for ELO calculations and tiebreaker logic. The 20,000-line tiebreaker model has no automated verification. I validated manually against 2020-2024 playoff results, but that's fragile. Future refactoring will add comprehensive test coverage.</p>

      <h2>Try It Yourself</h2>

      <p>The model runs live at <a href="https://michellepellon.com/portfolio/nfl-game-predictions.html">michellepellon.com/portfolio/nfl-game-predictions.html</a>. Predictions update automatically after every NFL game via GitHub Actions.</p>

      <p>The full codebase lives in a private repository, but I'm considering open-sourcing it after the 2025 season concludes. If you're interested in sports analytics, data engineering, or building prediction models, reach out.</p>

      <h2>Conclusion</h2>

      <p>Building an NFL prediction model taught me as much about data engineering as about football. The mathematics prove elegant: ELO ratings capture team strength in a single number. The architecture proves simple: DuckDB and dbt handle everything without distributed complexity. The results show promise: 57% accuracy across 10 weeks provides a solid baseline to improve upon.</p>

      <p>What started as a side project became a full-fledged analytics platform. Adding QB VALUE, hot simulations, travel adjustments, and playoff seed detection will push accuracy even higher. The gap with FiveThirtyEight is closing.</p>

      <p>More importantly, this demonstrates that modern data engineering enables individual developers to build sophisticated models previously requiring teams. One person, one laptop, one weekend can now accomplish what once took months and enterprise infrastructure.</p>

      <p>The democratization of data tools continues.</p>
    </div>
  </article>

  <footer>
    <div class="container">
      <p>&copy; 2025 Michelle Pellon. All rights reserved.</p>
    </div>
  </footer>
</body>
</html>
